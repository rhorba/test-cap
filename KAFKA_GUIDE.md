# üöÄ Guide Kafka - Syst√®me d'√âv√©nements

## üì° Vue d'ensemble

Le syst√®me de publication/consommation d'√©v√©nements utilise **Apache Kafka** comme message broker pour garantir :
- ‚úÖ **Persistance** : Les messages sont stock√©s sur disque
- ‚úÖ **Scalabilit√©** : Partitions et r√©plication
- ‚úÖ **Fiabilit√©** : Acknowledgment et retry automatique
- ‚úÖ **Performance** : Traitement asynchrone haute vitesse
- ‚úÖ **Tra√ßabilit√©** : Offset et historique complet

---

## üèóÔ∏è Architecture Kafka

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    VehiculeService                            ‚îÇ
‚îÇ              (Cr√©e un v√©hicule)                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ publish(VehiculeCreatedEvent)
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           KafkaDomainEventPublisher                           ‚îÇ
‚îÇ     ‚Ä¢ S√©rialise l'√©v√©nement en JSON                          ‚îÇ
‚îÇ     ‚Ä¢ D√©termine le topic (vehicule.created)                  ‚îÇ
‚îÇ     ‚Ä¢ Extrait la cl√© (garageId) pour partitionnement         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ KafkaTemplate.send()
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Apache Kafka                               ‚îÇ
‚îÇ  Topic: vehicule.created                                     ‚îÇ
‚îÇ  ‚Ä¢ 3 partitions                                              ‚îÇ
‚îÇ  ‚Ä¢ R√©tention: 7 jours                                        ‚îÇ
‚îÇ  ‚Ä¢ Compression: Snappy                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ @KafkaListener
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            VehiculeKafkaConsumer                              ‚îÇ
‚îÇ  ‚Ä¢ 3 consumers en parall√®le (concurrency=3)                  ‚îÇ
‚îÇ  ‚Ä¢ Acquittement manuel                                       ‚îÇ
‚îÇ  ‚Ä¢ Traite les √©v√©nements :                                   ‚îÇ
‚îÇ    - Notifications                                           ‚îÇ
‚îÇ    - Statistiques                                            ‚îÇ
‚îÇ    - Synchronisation externe                                 ‚îÇ
‚îÇ    - Indexation                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ D√©marrage Rapide

### 1. D√©marrer l'infrastructure Kafka

```powershell
# D√©marre Zookeeper, Kafka, Kafka UI et PostgreSQL
docker-compose up -d
```

**Services d√©marr√©s :**
- üü¢ **Zookeeper** : Port 2181
- üü¢ **Kafka Broker** : Port 9092
- üü¢ **Kafka UI** : http://localhost:8090
- üü¢ **PostgreSQL** : Port 5432
- üü¢ **pgAdmin** : http://localhost:5050

### 2. V√©rifier Kafka

```powershell
# V√©rifier que Kafka est en cours d'ex√©cution
docker ps | findstr kafka

# Logs Kafka
docker logs renault_kafka

# Acc√©der √† Kafka UI
start http://localhost:8090
```

### 3. Lancer l'application

```powershell
mvn spring-boot:run
```

### 4. Cr√©er un v√©hicule (d√©clenche l'√©v√©nement)

```powershell
$body = @{
    modeleId = "650e8400-e29b-41d4-a716-446655440001"
    brand = "Renault Zoe E-Tech"
    anneeFabrication = 2024
    typeCarburant = "ELECTRIQUE"
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:8080/api/v1/garages/550e8400-e29b-41d4-a716-446655440001/vehicules" `
    -Method POST -ContentType "application/json" -Body $body
```

---

## üìä Kafka UI - Visualisation

### Acc√©der √† Kafka UI
http://localhost:8090

### Fonctionnalit√©s disponibles :
- üìã **Topics** : Liste des topics et configuration
- üìä **Messages** : Visualisation des messages
- üë• **Consumers** : Groupes de consommateurs et lag
- ‚öôÔ∏è **Brokers** : √âtat des brokers Kafka

### V√©rifier les messages

1. Acc√©der √† Kafka UI : http://localhost:8090
2. Cliquer sur **Topics**
3. S√©lectionner `vehicule.created`
4. Onglet **Messages**
5. Voir les √©v√©nements publi√©s avec leur contenu JSON

---

## üìù Configuration Kafka

### application.yml

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    
    consumer:
      group-id: garage-service-group
      auto-offset-reset: earliest      # Lit depuis le d√©but
      enable-auto-commit: false        # Acquittement manuel
      
    producer:
      acks: all                        # Confirmation de tous les replicas
      retries: 3                       # Retry en cas d'√©chec
      properties:
        enable.idempotence: true       # √âvite les doublons
    
    listener:
      ack-mode: manual                 # Contr√¥le manuel de l'acquittement
```

### KafkaConfig.java

```java
@Configuration
@EnableKafka
public class KafkaConfig {
    
    public static final String VEHICULE_CREATED_TOPIC = "vehicule.created";
    
    @Bean
    public NewTopic vehiculeCreatedTopic() {
        return TopicBuilder.name(VEHICULE_CREATED_TOPIC)
                .partitions(3)           // 3 partitions pour parall√©lisme
                .replicas(1)             // 1 r√©plica (dev)
                .config("retention.ms", "604800000")  // 7 jours
                .config("compression.type", "snappy") // Compression
                .build();
    }
}
```

---

## üîë Concepts Cl√©s

### 1. Topics
**Topic** : `vehicule.created`
- Canal de communication pour les √©v√©nements de v√©hicule
- Cr√©√© automatiquement au d√©marrage
- Configur√© avec 3 partitions

### 2. Partitionnement
**Cl√© de partition** : `garageId`
- Tous les √©v√©nements d'un m√™me garage vont dans la m√™me partition
- **Garantit l'ordre** des √©v√©nements pour un garage donn√©
- Permet la **scalabilit√© horizontale**

### 3. Consumer Group
**Group ID** : `garage-service-group`
- Tous les consumers du m√™me groupe partagent les partitions
- Chaque message est consomm√© par **un seul** consumer du groupe
- Permet le **load balancing** automatique

### 4. Acquittement Manuel
- Le consumer acquitte manuellement apr√®s traitement r√©ussi
- En cas d'erreur, le message n'est pas acquitt√©
- Kafka le **r√©essaiera** automatiquement

### 5. Concurrency
**3 consumers en parall√®le**
- Chaque partition est trait√©e par un consumer d√©di√©
- Maximise le **throughput**
- Configuration : `factory.setConcurrency(3)`

---

## üîÑ Flux Complet

### 1. Publication (Producer)

```java
@Component
public class KafkaDomainEventPublisher implements DomainEventPublisher {
    
    @Override
    public void publish(Object event) {
        String topic = "vehicule.created";
        String key = event.getGarageId().toString();
        
        kafkaTemplate.send(topic, key, event)
            .whenComplete((result, ex) -> {
                if (ex == null) {
                    logger.info("‚úÖ √âv√©nement publi√© - partition: {}, offset: {}",
                               result.getRecordMetadata().partition(),
                               result.getRecordMetadata().offset());
                }
            });
    }
}
```

### 2. Consommation (Consumer)

```java
@Component
public class VehiculeKafkaConsumer {
    
    @KafkaListener(topics = "vehicule.created", groupId = "garage-service-group")
    public void onVehiculeCreated(
            @Payload VehiculeCreatedEvent event,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            Acknowledgment acknowledgment) {
        
        try {
            // Traiter l'√©v√©nement
            processEvent(event);
            
            // Acquitter le message
            acknowledgment.acknowledge();
            
        } catch (Exception e) {
            // En cas d'erreur, ne pas acquitter
            // Kafka r√©essaiera automatiquement
            throw new RuntimeException("Erreur de traitement", e);
        }
    }
}
```

---

## üìú Logs D√©taill√©s

### Exemple de logs lors de la cr√©ation d'un v√©hicule :

```
[INFO] VehiculeService - üöó Cr√©ation d'un nouveau v√©hicule pour le garage 550e8400...
[INFO] KafkaDomainEventPublisher - üì¢ [KAFKA PUBLISHER] Publication de l'√©v√©nement: VehiculeCreatedEvent vers le topic: vehicule.created
[INFO] KafkaDomainEventPublisher - ‚úÖ [KAFKA] √âv√©nement publi√© avec succ√®s sur le topic 'vehicule.created' - partition: 2, offset: 15
[INFO] VehiculeService - ‚úÖ V√©hicule cr√©√© avec succ√®s: 789e4567...

--- Consumer (Thread kafka-listener-1) ---
[INFO] VehiculeKafkaConsumer - üöó [KAFKA CONSUMER] R√©ception d'un √©v√©nement VehiculeCreatedEvent
[INFO] VehiculeKafkaConsumer -    üìç Partition: 2, Offset: 15
[INFO] VehiculeKafkaConsumer -    ‚Üí V√©hicule ID: 789e4567...
[INFO] VehiculeKafkaConsumer -    ‚Üí Garage ID: 550e8400...
[INFO] VehiculeKafkaConsumer -    ‚Üí Marque: Renault Zoe E-Tech
[INFO] VehiculeKafkaConsumer - ‚öôÔ∏è  [KAFKA] Traitement de l'√©v√©nement en cours...
[INFO] VehiculeKafkaConsumer - üìß [Notification] Envoi d'email
[INFO] VehiculeKafkaConsumer - üìä [Statistiques] Mise √† jour: +1 v√©hicule
[INFO] VehiculeKafkaConsumer - üîÑ [Synchronisation] Mise √† jour du syst√®me externe
[INFO] VehiculeKafkaConsumer - üîç [Indexation] Indexation dans Elasticsearch
[INFO] VehiculeKafkaConsumer - ‚úÖ [KAFKA] √âv√©nement trait√© avec succ√®s
[DEBUG] VehiculeKafkaConsumer - ‚úÖ Message acquitt√© - partition: 2, offset: 15
```

---

## üß™ Tests

### Test d'Int√©gration avec Embedded Kafka

```java
@SpringBootTest
@EmbeddedKafka(partitions = 1, topics = {"vehicule.created"})
class KafkaEventIntegrationTest {
    
    @Test
    void shouldPublishKafkaEventWhenVehiculeIsCreated() throws InterruptedException {
        // Given
        CreateVehiculeRequest request = new CreateVehiculeRequest(...);
        
        // When
        vehiculeService.createVehicule(garageId, request);
        
        // Then
        ConsumerRecord<String, VehiculeCreatedEvent> received = 
            records.poll(10, TimeUnit.SECONDS);
        
        assertThat(received).isNotNull();
        assertThat(received.value().getVehiculeId()).isEqualTo(...);
    }
}
```

### Lancer les tests

```powershell
# Tous les tests
mvn test

# Tests Kafka uniquement
mvn test -Dtest=KafkaEventIntegrationTest
```

---

## üîç Monitoring & Debug

### 1. Kafka UI (Recommand√©)
http://localhost:8090
- Vue d'ensemble du cluster
- Messages en temps r√©el
- Consumer lag
- M√©triques

### 2. CLI Kafka (via Docker)

```powershell
# Lister les topics
docker exec -it renault_kafka kafka-topics --list --bootstrap-server localhost:9092

# D√©tails d'un topic
docker exec -it renault_kafka kafka-topics --describe --topic vehicule.created --bootstrap-server localhost:9092

# Consommer des messages (debug)
docker exec -it renault_kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic vehicule.created --from-beginning

# Produire un message (test)
docker exec -it renault_kafka kafka-console-producer --broker-list localhost:9092 --topic vehicule.created
```

### 3. Consumer Groups

```powershell
# Lister les consumer groups
docker exec -it renault_kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list

# D√©tails d'un group (lag, offset)
docker exec -it renault_kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group garage-service-group
```

---

## ‚öôÔ∏è Configuration Avanc√©e

### Production-Ready Settings

```yaml
spring:
  kafka:
    bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092  # Cluster
    
    producer:
      acks: all
      retries: 10
      max-in-flight-requests-per-connection: 5
      properties:
        enable.idempotence: true
        compression.type: snappy
        linger.ms: 10                    # Batching
        batch.size: 32768                # 32 KB
    
    consumer:
      max-poll-records: 500
      max-poll-interval-ms: 300000       # 5 minutes
      session-timeout-ms: 10000
      heartbeat-interval-ms: 3000
      
    listener:
      concurrency: 10                    # 10 consumers
      ack-mode: manual
```

### Topic avec R√©plication (Production)

```java
@Bean
public NewTopic vehiculeCreatedTopic() {
    return TopicBuilder.name("vehicule.created")
            .partitions(10)              // Plus de partitions
            .replicas(3)                 // 3 r√©plicas pour HA
            .config("min.insync.replicas", "2")  // Minimum 2 replicas sync
            .config("retention.ms", "2592000000") // 30 jours
            .build();
}
```

---

## üö® Gestion des Erreurs

### 1. Retry Automatique
Si le consumer √©choue, Kafka r√©essaie automatiquement :
- Le message n'est pas acquitt√©
- Kafka le renvoie apr√®s un d√©lai
- Configurable via `max.poll.interval.ms`

### 2. Dead Letter Topic (DLT)
Pour les messages qui √©chouent apr√®s plusieurs retries :

```java
@Bean
public KafkaListenerContainerFactory<?> kafkaListenerContainerFactory() {
    factory.setCommonErrorHandler(
        new DefaultErrorHandler(
            new DeadLetterPublishingRecoverer(kafkaTemplate),
            new FixedBackOff(1000L, 3L)  // 3 retries avec 1s entre chaque
        )
    );
    return factory;
}
```

---

## üìä Avantages de Kafka vs Spring Events

| Crit√®re | Spring Events | Apache Kafka |
|---------|---------------|--------------|
| **Persistance** | ‚ùå Non | ‚úÖ Oui (disque) |
| **Scalabilit√©** | ‚ö†Ô∏è  Limit√©e | ‚úÖ Excellente |
| **Fiabilit√©** | ‚ö†Ô∏è  En m√©moire | ‚úÖ R√©plication |
| **Historique** | ‚ùå Non | ‚úÖ R√©tention configurable |
| **Multi-instances** | ‚ùå Local | ‚úÖ Distribu√© |
| **Replay** | ‚ùå Impossible | ‚úÖ Rejouer les messages |
| **Monitoring** | ‚ö†Ô∏è  Basique | ‚úÖ Complet |
| **Complexit√©** | ‚úÖ Simple | ‚ö†Ô∏è  Moyenne |
| **Infrastructure** | ‚úÖ Aucune | ‚ö†Ô∏è  Kafka requis |

---

## üéØ Use Cases

### ‚úÖ Quand utiliser Kafka :
- Architecture microservices distribu√©e
- Besoin de persistance des √©v√©nements
- Historique et replay n√©cessaires
- Haute volum√©trie d'√©v√©nements
- Int√©gration avec d'autres syst√®mes
- Event Sourcing / CQRS

### ‚ö†Ô∏è  Quand utiliser Spring Events :
- Application monolithique
- √âv√©nements en m√©moire suffisants
- Faible volum√©trie
- Prototype rapide

---

## üöÄ √âvolutions Futures

### Phase 2 : Schema Registry
```yaml
spring:
  kafka:
    properties:
      schema.registry.url: http://localhost:8081
```
- Validation des sch√©mas avec Avro
- Versioning des √©v√©nements
- Compatibilit√© assur√©e

### Phase 3 : Kafka Streams
- Agr√©gation en temps r√©el
- Transformations de flux
- Fen√™trage temporel

### Phase 4 : Kafka Connect
- Int√©gration avec bases de donn√©es
- Synchronisation automatique
- ETL en temps r√©el

---

## üìû Ressources

### Documentation
- **Kafka UI** : http://localhost:8090
- **Kafka Docs** : https://kafka.apache.org/documentation/
- **Spring Kafka** : https://spring.io/projects/spring-kafka

### Commandes Utiles
```powershell
# D√©marrer l'infrastructure
docker-compose up -d

# Arr√™ter l'infrastructure
docker-compose down

# Voir les logs Kafka
docker logs -f renault_kafka

# Nettoyer les donn√©es
docker-compose down -v
```

---

**‚úÖ Syst√®me Kafka op√©rationnel et production-ready !** üéâ
